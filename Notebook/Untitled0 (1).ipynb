{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMjyjT6aFaIPIQS2VeWq6g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Za34wmAKzZIN","executionInfo":{"status":"ok","timestamp":1758282498976,"user_tz":-330,"elapsed":4,"user":{"displayName":"Mridul","userId":"15215068258986362506"}}},"outputs":[],"source":["import json\n","\n","def get_current_weather(location, unit=\"fahrenheit\"):\n","    \"\"\"\n","    Get the current weather in a given location.\n","\n","    Args:\n","        location (str): The city and state, e.g., \"San Francisco, CA\".\n","        unit (str): The unit of temperature. Defaults to \"fahrenheit\".\n","\n","    Returns:\n","        dict: A dictionary containing weather information.\n","    \"\"\"\n","    if \"boston\" in location.lower():\n","        return {\"temperature\": 72, \"unit\": unit, \"description\": \"Sunny\"}\n","    elif \"new york\" in location.lower():\n","        return {\"temperature\": 65, \"unit\": unit, \"description\": \"Cloudy\"}\n","    else:\n","        return {\"temperature\": \"N/A\", \"unit\": unit, \"description\": \"Unknown\"}"]},{"cell_type":"code","source":["tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"get_current_weather\",\n","            \"description\": \"Get the current weather in a given location\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"location\": {\n","                        \"type\": \"string\",\n","                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n","                    },\n","                    \"unit\": {\n","                        \"type\": \"string\",\n","                        \"enum\": [\"celsius\", \"fahrenheit\"],\n","                    },\n","                },\n","                \"required\": [\"location\"],\n","            },\n","        },\n","    }\n","]"],"metadata":{"id":"iUjT_TVszhRE","executionInfo":{"status":"ok","timestamp":1758282523046,"user_tz":-330,"elapsed":2,"user":{"displayName":"Mridul","userId":"15215068258986362506"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["pip install openai\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v6J9y2PMzk4r","executionInfo":{"status":"ok","timestamp":1758282552596,"user_tz":-330,"elapsed":8146,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"64dc9576-b36d-42d3-91a2-1c8b3651b33a"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.11.7)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"]}]},{"cell_type":"code","source":["from openai import OpenAI\n","\n","# It's best practice to use environment variables for API keys\n","# import os\n","# client = OpenAI(api_key=os.environ.get(\"GEMINI_API_KEY\"), base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n","\n","# For this example, we'll use a hardcoded key as in your original question\n","client = OpenAI(\n","    api_key=\"AIzaSyDex6EgkbkSMxSd3Pjv6B7N1hFUGXLCkNE\",\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",")\n","\n","# This is the initial user message.\n","messages = [{\"role\": \"user\", \"content\": \"What's the weather like in Boston today?\"}]\n","\n","try:\n","    response = client.chat.completions.create(\n","        model=\"gemini-2.5-flash\",\n","        messages=messages,\n","        tools=tools,\n","        tool_choice=\"auto\"  # The model decides whether to use the tool\n","    )\n","\n","    # Get the response message from the first choice\n","    response_message = response.choices[0].message\n","\n","    # Check if the model decided to call a tool\n","    if response_message.tool_calls:\n","        tool_call = response_message.tool_calls[0]\n","        function_name = tool_call.function.name\n","        function_args = json.loads(tool_call.function.arguments)\n","\n","        print(f\"Model wants to call the function: {function_name}\")\n","        print(f\"With arguments: {function_args}\")\n","\n","        # At this point, you would call your local function.\n","        available_functions = {\"get_current_weather\": get_current_weather}\n","        function_to_call = available_functions[function_name]\n","        function_response = function_to_call(**function_args)\n","\n","        print(f\"Function output: {function_response}\")\n","\n","        # Now, you need to send the function's output back to the model.\n","        # This is a critical step in the \"multi-turn\" tool-use pattern.\n","        messages.append(response_message)\n","        messages.append({\n","            \"role\": \"tool\",\n","            \"tool_call_id\": tool_call.id,\n","            \"name\": function_name,\n","            \"content\": json.dumps(function_response),\n","        })\n","\n","        # Make a second request to get the final, human-readable response.\n","        second_response = client.chat.completions.create(\n","            model=\"gemini-2.5-flash\",\n","            messages=messages\n","        )\n","\n","        final_message = second_response.choices[0].message\n","        print(\"\\nFinal response from the model:\")\n","        print(final_message.content)\n","\n","except Exception as e:\n","    print(f\"An error occurred: {e}\")"],"metadata":{"id":"wJzMWPFJzptb","executionInfo":{"status":"ok","timestamp":1758282568396,"user_tz":-330,"elapsed":9482,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"664c7854-bd45-4636-c24c-fd5a6e62fbf7","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Model wants to call the function: get_current_weather\n","With arguments: {'location': 'Boston, MA'}\n","Function output: {'temperature': 72, 'unit': 'fahrenheit', 'description': 'Sunny'}\n","\n","Final response from the model:\n","The weather in Boston today is sunny with a temperature of 72 degrees Fahrenheit.\n"]}]}]}