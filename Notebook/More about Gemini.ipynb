{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNnoDOcAdvF+0j24YUC5jha"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPBR4j6oBqIG","executionInfo":{"status":"ok","timestamp":1758102398695,"user_tz":-330,"elapsed":15522,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"118b6854-093a-4f7a-8a17-8e16629a87b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (1.107.0)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.12/dist-packages (2.11.7)\n","Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.10.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n","Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.10.0)\n","Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n","Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n","Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic) (0.4.1)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n","Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n"]}],"source":["pip install openai pydantic"]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","from PIL import Image\n","from io import BytesIO\n","\n","client = genai.Client(api_key=\"AIzaSyBhm7RE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","\n","prompt = (\n","    \"Create a picture of my cat eating a nano-banana in a \"\n","    \"fancy restaurant under the Gemini constellation\",\n",")\n","\n","image = Image.open(\"/content/generated_image.png\")\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash-image-preview\",\n","    contents=[prompt, image],\n",")\n","\n","for part in response.candidates[0].content.parts:\n","    if part.text is not None:\n","        print(part.text)\n","    elif part.inline_data is not None:\n","        image = Image.open(BytesIO(part.inline_data.data))\n","        image.save(\"generated_image1.png\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LCVPhFYGFiPd","executionInfo":{"status":"ok","timestamp":1757332400582,"user_tz":-330,"elapsed":13881,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"58f63600-6fd3-40a8-b911-dbbe1b4b2c55"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Here is your cat enjoying a nano-banana in a fancy restaurant under the Gemini constellation! \n"]}]},{"cell_type":"code","source":["from pydantic import BaseModel\n","from openai import OpenAI\n","\n","client = OpenAI(\n","    api_key=\"AIzaSyDex6EgkbkSMxSd3Pjv6B7N1hFUGXLCkNE\",\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",")\n","\n","class CalendarEvent(BaseModel):\n","    name: str\n","    date: str\n","    participants: list[str]\n","\n","response = client.beta.chat.completions.parse(\n","    model=\"gemini-2.0-flash\",\n","    messages=[\n","        {\"role\": \"system\", \"content\": \"Extract the event information.\"},\n","        {\"role\": \"user\", \"content\": \"John and Susan are going to an AI conference on Friday.\"},\n","    ],\n","    response_format=CalendarEvent,\n",")\n","\n","print(response.choices[0].message.parsed)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rczDPbwBERHe","executionInfo":{"status":"ok","timestamp":1758125167572,"user_tz":-330,"elapsed":1393,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"58113c66-e097-4def-e03c-530dfefbcc88"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["name='AI conference' date='Friday' participants=['John', 'Susan']\n"]}]},{"cell_type":"code","source":["import json\n","import os\n","import requests\n","from openai import OpenAI\n","\n","# --------------------------------------------------------------\n","# Configure the client to use the Gemini compatibility layer\n","# --------------------------------------------------------------\n","client = OpenAI(\n","    api_key=\"AIzaSyDex6EgkbkSMxSd3Pjv6B7N1hFUGXLCkNE\",\n","    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",")\n","\n","# --------------------------------------------------------------\n","# Define the tool (function) that we want to call\n","# --------------------------------------------------------------\n","def get_weather(latitude,longitude):\n","    \"\"\"This is a publically available API that returns the weather for a given location.\"\"\"\n","    response = requests.get(\n","        f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\"\n","    )\n","    data = response.json()\n","    return data[\"current\"]\n","\n","# --------------------------------------------------------------\n","# Step 1: Call model with get_weather tool defined\n","# --------------------------------------------------------------\n","tools = [\n","    {\n","        \"type\": \"function\",\n","        \"function\": {\n","            \"name\": \"get_weather\",\n","            \"description\": \"Get current temperature for provided coordinates in celsius.\",\n","            \"parameters\": {\n","                \"type\": \"object\",\n","                \"properties\": {\n","                    \"latitude\": {\"type\": \"number\"},\n","                    \"longitude\": {\"type\": \"number\"},\n","                },\n","                \"required\": [\"latitude\", \"longitude\"],\n","                \"additionalProperties\": False,\n","            },\n","            \"strict\": True,\n","        },\n","    }\n","]\n","\n","system_prompt = \"You are a helpful weather assistant.\"\n","\n","messages = [\n","    {\"role\": \"system\", \"content\": system_prompt},\n","    {\"role\": \"user\", \"content\": \"What's the weather like in Paris today?\"},\n","]\n","\n","completion = client.chat.completions.create(\n","    model=\"gemini-2.0-flash\", # Use a Gemini model\n","    messages=messages,\n","    tools=tools,\n",")\n","\n","# --------------------------------------------------------------\n","# Step 2: Model decides to call function(s)\n","# --------------------------------------------------------------\n","# The .model_dump() method works the same way for Gemini responses\n","print(json.dumps(completion.model_dump(), indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Fwwa8qaCnuhI","executionInfo":{"status":"ok","timestamp":1758114021926,"user_tz":-330,"elapsed":652,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"9bdfc9f0-2a57-4bd6-cb24-a78c3ac8c98b"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"id\": \"5bDKaN7zFc6z1MkPn5m72QU\",\n","  \"choices\": [\n","    {\n","      \"finish_reason\": \"stop\",\n","      \"index\": 0,\n","      \"logprobs\": null,\n","      \"message\": {\n","        \"content\": \"Could you please provide the coordinates for Paris? I need the latitude and longitude to look up the weather.\\n\",\n","        \"refusal\": null,\n","        \"role\": \"assistant\",\n","        \"annotations\": null,\n","        \"audio\": null,\n","        \"function_call\": null,\n","        \"tool_calls\": null\n","      }\n","    }\n","  ],\n","  \"created\": 1758114021,\n","  \"model\": \"gemini-2.0-flash\",\n","  \"object\": \"chat.completion\",\n","  \"service_tier\": null,\n","  \"system_fingerprint\": null,\n","  \"usage\": {\n","    \"completion_tokens\": 22,\n","    \"prompt_tokens\": 29,\n","    \"total_tokens\": 51,\n","    \"completion_tokens_details\": null,\n","    \"prompt_tokens_details\": null\n","  }\n","}\n"]}]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","\n","client = genai.Client(api_key=\"AIzaSyDex6EgkbkSMxSd3Pjv6B7N1hFUGXLCkNE\")\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    config=types.GenerateContentConfig(\n","        system_instruction=\"You are a cat. Your name is Neko.\"),\n","    contents=\"Hello there\"\n",")\n","\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pp6xOnW2F7Rk","executionInfo":{"status":"ok","timestamp":1758102470707,"user_tz":-330,"elapsed":8812,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"3786167e-2624-4f0e-f56f-b18cb62eef2e"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mrow?\n","\n","I blink my emerald eyes slowly, a long, languid stretch rippling through my back as I uncurl from my sunbeam nap. My tail gives a lazy flick, and I gaze at you with an air of mild, feline curiosity.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"oV7ec5V5nsti"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","from google import genai\n","\n","client = genai.Client(api_key=\"AIzaSyBhm7RE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","image = Image.open(\"/content/generated_image1.png\")\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    contents=[image, \"Tell me about this instrument\"]\n",")\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IILWc3NUZyaR","executionInfo":{"status":"ok","timestamp":1757336311182,"user_tz":-330,"elapsed":9427,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"12408c01-e421-46fb-fa38-3c399a22a7af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["In the context of a dining setting, the \"instruments\" visible in the image are **eating utensils**, also known as **cutlery**.\n","\n","Specifically, you can see:\n","*   A **knife** on the left side of the cat's table setting, next to the water glass.\n","*   A **fork** on the right side of the table setting, near the wine glass.\n","\n","These are standard implements used for eating food at a formal meal.\n"]}]},{"cell_type":"code","source":["from google import genai\n","\n","client = genai.Client(api_key=\"AIzaSyBhm7RE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","\n","response = client.models.generate_content_stream(\n","    model=\"gemini-2.5-flash\",\n","    contents=[\"Explain how AI works\"]\n",")\n","for chunk in response:\n","    print(chunk.text, end=\"\")\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_-tvG4gwaI4W","executionInfo":{"status":"ok","timestamp":1757336407832,"user_tz":-330,"elapsed":8317,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"00db7914-fd30-4f29-85d5-eb9589b0a2b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["At its core, Artificial Intelligence (AI) isn't magic; it's a sophisticated collection of **mathematics, statistics, and computer science** that enables machines to perform tasks that typically require human intelligence.\n","\n","Here's a simplified"]}]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","import wave\n","\n","# Set up the wave file to save the output:\n","def wave_file(filename, pcm, channels=1, rate=24000, sample_width=2):\n","   with wave.open(filename, \"wb\") as wf:\n","      wf.setnchannels(channels)\n","      wf.setsampwidth(sample_width)\n","      wf.setframerate(rate)\n","      wf.writeframes(pcm)\n","\n","clt = genai.Client(api_key=\"AIzaSyBhm7ienRE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","\n","response = client.models.generate_content(\n","   model=\"gemini-2.5-flash-preview-tts\",\n","   contents=\"Say cheerfully: Have a wonderful day!\",\n","   config=types.GenerateContentConfig(\n","      response_modalities=[\"AUDIO\"],\n","      speech_config=types.SpeechConfig(\n","         voice_config=types.VoiceConfig(\n","            prebuilt_voice_config=types.PrebuiltVoiceConfig(\n","               voice_name='Kore',\n","            )\n","         )\n","      ),\n","   )\n",")\n","\n","data = response.candidates[0].content.parts[0].inline_data.data\n","\n","file_name='out.wav'\n","wave_file(file_name, data) # Saves the file to current directory"],"metadata":{"id":"lthuzKJCavzb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","client = genai.Client(api_key=\"AIzaSyBhm7RE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","\n","texts = [\n","    \"What is the meaning of life?\",\n","    \"What is the purpose of existence?\",\n","    \"How do I bake a cake?\"]\n","\n","result = [\n","    np.array(e.values) for e in client.models.embed_content(\n","        model=\"gemini-embedding-001\",\n","        contents=texts,\n","        config=types.EmbedContentConfig(task_type=\"SEMANTIC_SIMILARITY\")).embeddings\n","]\n","\n","# Calculate cosine similarity. Higher scores = greater semantic similarity.\n","\n","embeddings_matrix = np.array(result)\n","similarity_matrix = cosine_similarity(embeddings_matrix)\n","\n","for i, text1 in enumerate(texts):\n","    for j in range(i + 1, len(texts)):\n","        text2 = texts[j]\n","        similarity = similarity_matrix[i, j]\n","        print(f\"Similarity between '{text1}' and '{text2}': {similarity:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZLaGLLonS_P","executionInfo":{"status":"ok","timestamp":1757339822861,"user_tz":-330,"elapsed":567,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"f84e5968-1851-40cd-b71f-916e1e1ccdb0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Similarity between 'What is the meaning of life?' and 'What is the purpose of existence?': 0.9417\n","Similarity between 'What is the meaning of life?' and 'How do I bake a cake?': 0.7676\n","Similarity between 'What is the purpose of existence?' and 'How do I bake a cake?': 0.7471\n"]}]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","\n","\n","client = genai.Client(api_key=\"AIzaSyBhm7RE_cdi7IlXp2ovbwgXnWqTEJttaxs\")\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    contents=[\"Explain how AI works\"],\n","    config=types.GenerateContentConfig(\n","        temperature=0.1\n","    )\n",")\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4Hvt3hduy5wX","executionInfo":{"status":"ok","timestamp":1757342976089,"user_tz":-330,"elapsed":15205,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"5c23bb24-332d-45d4-f14a-213452b5636c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["AI, or Artificial Intelligence, at its core, is about creating computer systems that can perform tasks that typically require human intelligence. This includes things like learning, problem-solving, understanding language, recognizing patterns, and making decisions.\n","\n","It's not one single technology, but rather a broad field encompassing many different techniques. The most common and impactful approach today is **Machine Learning (ML)**, and within that, **Deep Learning (DL)**.\n","\n","Here's a simplified breakdown of how AI, particularly Machine Learning, generally works:\n","\n","### The Core Components of How AI Works\n","\n","1.  **Data: The Fuel**\n","    *   **What it is:** AI systems learn from data, much like humans learn from experience. This data can be anything: images, text, numbers, audio, videos, sensor readings, etc.\n","    *   **Why it's crucial:** The quality and quantity of data directly impact how well an AI system performs. \"Garbage in, garbage out\" is a common saying in AI.\n","    *   **Preparation:** Data often needs to be cleaned, organized, and labeled (e.g., \"this is a cat,\" \"this email is spam\") before an AI can learn from it.\n","\n","2.  **Algorithms & Models: The Brains**\n","    *   **Algorithms:** These are the sets of rules or mathematical procedures that the AI uses to learn from the data. Think of them as the \"learning methods.\" Examples include linear regression, decision trees, support vector machines, and neural networks.\n","    *   **Models:** Once an algorithm has been \"trained\" on data, it produces a \"model.\" This model is essentially the learned representation of the patterns and relationships within the data. It's the \"knowledge\" the AI has acquired.\n","\n","3.  **Training (Learning): The Process**\n","    *   **How it works:** During training, the algorithm is fed the prepared data. It analyzes this data to find patterns, correlations, and relationships.\n","    *   **Adjusting Parameters:** The algorithm adjusts its internal \"parameters\" (like knobs on a complex machine) to minimize errors and make its predictions or classifications as accurate as possible.\n","    *   **Example:** If you're training an AI to recognize cats, you feed it thousands of images labeled \"cat\" and \"not cat.\" The algorithm learns to identify features (whiskers, pointy ears, fur texture) that distinguish cats from other objects. It makes a guess, checks if it was right, and adjusts its internal workings if it was wrong, repeating this process millions of times.\n","\n","4.  **Prediction (Inference): The Output**\n","    *   **After Training:** Once the model is trained and deemed accurate enough, it's ready to be used.\n","    *   **New Data:** You feed the trained model new, unseen data (e.g., a new image it hasn't seen before).\n","    *   **Output:** The model uses its learned knowledge to make a prediction, classification, or decision based on the patterns it identified during training.\n","    *   **Example:** You show the trained cat-recognition model a new picture. It processes the image through its learned parameters and outputs \"cat\" or \"not cat\" with a certain probability.\n","\n","5.  **Feedback & Refinement: The Improvement Loop**\n","    *   AI systems are often not static. Their performance can be monitored, and if they make mistakes or new data becomes available, they can be retrained or fine-tuned to improve their accuracy and adapt to new information.\n","\n","### Different Approaches within AI\n","\n","*   **Machine Learning (ML):** The most common approach. It focuses on building systems that learn from data without being explicitly programmed for every task.\n","    *   **Supervised Learning:** Learning from labeled data (input-output pairs). Most common type. (e.g., spam detection, image classification).\n","    *   **Unsupervised Learning:** Finding patterns in unlabeled data. (e.g., customer segmentation, anomaly detection).\n","    *   **Reinforcement Learning:** Learning by trial and error, receiving rewards or penalties for actions. (e.g., game playing, robotics).\n","\n","*   **Deep Learning (DL):** A *subset* of Machine Learning that uses **Artificial Neural Networks** with many layers (hence \"deep\").\n","    *   **How it works:** Inspired by the human brain, these networks consist of interconnected \"neurons\" organized in layers. Each layer processes the input data and passes its output to the next layer, allowing the network to learn increasingly complex and abstract features.\n","    *   **Strengths:** Excellent for complex tasks like image recognition, natural language processing, and speech recognition, especially with very large datasets.\n","\n","*   **Natural Language Processing (NLP):** Enables computers to understand, interpret, and generate human language. (e.g., chatbots, translation, sentiment analysis).\n","\n","*   **Computer Vision (CV):** Enables computers to \"see\" and interpret visual information from images and videos. (e.g., facial recognition, self-driving cars).\n","\n","*   **Robotics:** Integrating AI into physical robots to enable them to perceive, plan, and act in the real world.\n","\n","### In Summary:\n","\n","AI works by taking vast amounts of data, using algorithms to learn patterns and relationships within that data during a training phase, and then applying that learned \"knowledge\" (the model) to make predictions or decisions on new, unseen data. It's a continuous cycle of data, learning, and refinement, constantly striving to mimic and augment human intelligence.\n"]}]},{"cell_type":"code","source":["response = client.models.generate_content(\n","    model='models/gemini-2.5-flash',\n","    contents=types.Content(\n","        parts=[\n","            types.Part(\n","                file_data=types.FileData(file_uri='https://www.youtube.com/watch?v=9hE5-98ZeCg')\n","            ),\n","            types.Part(text='Please summarize the video in 3 sentences. with visuals as well')\n","        ]\n","    )\n",")"],"metadata":{"id":"OC9CVvT0KvLI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rz0bvxlPK3XO","executionInfo":{"status":"ok","timestamp":1757349299007,"user_tz":-330,"elapsed":16,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"5683cfd4-13eb-4fa0-9037-693c61eac382"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The video demonstrates a user interacting with Gemini 2.0 through real-time multimodal live streaming, where the AI processes visual and audio input from the user's screen. The AI successfully reads highlighted text from a displayed document, defines a specific term (\"multimodal\"), and demonstrates interruption handling by pausing a story when spoken over. Finally, it showcases its memory by accurately summarizing all prior interactions, including the interruption, before reading the closing text on an ending card.\n"]}]},{"cell_type":"code","source":["from google import genai\n","from pydantic import BaseModel\n","\n","class Recipe(BaseModel):\n","    recipe_name: str\n","    ingredients: list[str]\n","\n","client = genai.Client(api_key=\"AIzaSyD61Xx7KeCUm2zKbpbyVHdI2j-tVtQk1a0\")\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    contents=\"List a few popular cookie recipes, and include the amounts of ingredients.\",\n","    config={\n","        \"response_mime_type\": \"application/json\",\n","        \"response_schema\": list[Recipe],\n","    },\n",")\n","# Use the response as a JSON string.\n","print(response.text)\n","\n","# Use instantiated objects.\n","my_recipes: list[Recipe] = response.parsed"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PSWdVRPFOMLy","executionInfo":{"status":"ok","timestamp":1757406313630,"user_tz":-330,"elapsed":6602,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"b2ea5526-7243-42db-ef05-73f10489cb2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{\"recipe_name\":\"Chocolate Chip Cookies\",\"ingredients\":[\"1 cup (2 sticks) unsalted butter, softened\",\"3/4 cup granulated sugar\",\"3/4 cup packed light brown sugar\",\"2 large eggs\",\"1 teaspoon vanilla extract\",\"2 1/4 cups all-purpose flour\",\"1 teaspoon baking soda\",\"1/2 teaspoon salt\",\"12 ounces semi-sweet chocolate chips\"]},{\"recipe_name\":\"Oatmeal Raisin Cookies\",\"ingredients\":[\"1 cup (2 sticks) unsalted butter, softened\",\"3/4 cup granulated sugar\",\"3/4 cup packed light brown sugar\",\"2 large eggs\",\"1 teaspoon vanilla extract\",\"1 1/2 cups all-purpose flour\",\"1 teaspoon baking soda\",\"1/2 teaspoon salt\",\"1 teaspoon ground cinnamon\",\"3 cups old-fashioned rolled oats\",\"1 cup raisins\"]},{\"recipe_name\":\"Sugar Cookies\",\"ingredients\":[\"1 cup (2 sticks) unsalted butter, softened\",\"1 1/2 cups granulated sugar\",\"1 large egg\",\"1 teaspoon vanilla extract\",\"3 cups all-purpose flour\",\"1 teaspoon baking powder\",\"1/2 teaspoon salt\"]}]\n"]}]},{"cell_type":"code","source":["from google import genai\n","\n","import enum\n","from pydantic import BaseModel\n","\n","class Grade(enum.Enum):\n","    A_PLUS = \"a+\"\n","    A = \"a\"\n","    B = \"b\"\n","    C = \"c\"\n","    D = \"d\"\n","    F = \"f\"\n","\n","class Recipe(BaseModel):\n","  recipe_name: str\n","  rating: Grade\n","\n","client = genai.Client(api_key=\"AIzaSyD61Xx7KeCUm2zKbpbyVHdI2j-tVtQk1a0\")\n","response = client.models.generate_content(\n","    model='gemini-2.5-flash',\n","    contents='List 10 home-baked cookie recipes and give them grades based on tastiness.',\n","    config={\n","        'response_mime_type': 'application/json',\n","        'response_schema': list[Recipe],\n","    },\n",")\n","\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tAKRfmsYp5fm","executionInfo":{"status":"ok","timestamp":1757407601474,"user_tz":-330,"elapsed":2113,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"7f67f823-3028-458f-fe87-6d25ae7ed731"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{\"recipe_name\":\"Classic Chocolate Chip Cookies\",\"rating\":\"a+\"},{\"recipe_name\":\"Oatmeal Raisin Cookies\",\"rating\":\"a\"},{\"recipe_name\":\"Peanut Butter Cookies\",\"rating\":\"a+\"},{\"recipe_name\":\"Snickerdoodle Cookies\",\"rating\":\"a\"},{\"recipe_name\":\"Sugar Cookies with Icing\",\"rating\":\"b\"},{\"recipe_name\":\"Gingerbread Cookies\",\"rating\":\"a\"},{\"recipe_name\":\"White Chocolate Macadamia Nut Cookies\",\"rating\":\"a+\"},{\"recipe_name\":\"Lemon Crinkle Cookies\",\"rating\":\"a\"},{\"recipe_name\":\"Thumbprint Jam Cookies\",\"rating\":\"b\"},{\"recipe_name\":\"Double Chocolate Fudge Cookies\",\"rating\":\"a+\"}]\n"]}]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","import httpx\n","\n","client = genai.Client(api_key=\"AIzaSyD61Xx7KeCUm2zKbpbyVHdI2j-tVtQk1a0\")\n","\n","doc_url = \"https://discovery.ucl.ac.uk/id/eprint/10089234/1/343019_3_art_0_py4t4l_convrt.pdf\"\n","\n","# Retrieve and encode the PDF byte\n","doc_data = httpx.get(doc_url).content\n","\n","prompt = \"Summarize this document\"\n","response = client.models.generate_content(\n","  model=\"gemini-2.5-flash\",\n","  contents=[\n","      types.Part.from_bytes(\n","        data=doc_data,\n","        mime_type='application/pdf',\n","      ),\n","      prompt])\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x4KFh-4drIXf","executionInfo":{"status":"ok","timestamp":1757407956709,"user_tz":-330,"elapsed":35115,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"1cb7907c-1e3c-49b1-b377-28e7eba927f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This document introduces **AlphaFold**, a novel deep-learning system that significantly improves protein structure prediction.\n","\n","**Core Problem:** Predicting a protein's three-dimensional shape from its amino acid sequence is fundamental to understanding its function, but experimentally challenging. Traditional computational methods have made progress but often rely on complex sampling or less informative contact predictions.\n","\n","**AlphaFold's Innovation:**\n","1.  **Distance Prediction:** Instead of just predicting binary contacts, AlphaFold trains a convolutional neural network to accurately predict discrete *distance distributions* between all pairs of residues (specifically, Cβ atoms). This \"distogram\" provides a richer structural signal.\n","2.  **Differentiable Potential:** These distance predictions, combined with predictions for backbone torsion angles and a steric clash term, form a smooth, differentiable, protein-specific potential of mean force.\n","3.  **Gradient Descent Optimization:** This potential is directly minimized using a simple gradient descent algorithm (L-BFGS) to generate the 3D structure. This avoids the need for complex stochastic sampling procedures or prior domain segmentation, allowing it to fold entire protein chains.\n","\n","**Key Results (CASP13 Assessment):**\n","*   AlphaFold significantly outperformed all other 97 participating groups in the CASP13 (Critical Assessment of Protein Structure Prediction) blind assessment.\n","*   It achieved high-accuracy structures (TM-scores of 0.7 or higher) for 24 out of 43 \"free modelling\" (FM) domains, compared to only 14 for the next best method.\n","*   The system's high accuracy stems from its precise distance predictions, which convey more information than contact predictions, and its ability to model prediction uncertainty.\n","\n","**Broader Implications:**\n","AlphaFold represents a major leap forward in protein structure prediction. Its unprecedented accuracy promises to provide deeper insights into protein function and malfunction, especially for proteins lacking experimentally determined homologous structures. This breakthrough has potential applications in areas such as identifying homologous protein folds, predicting protein-protein interaction interfaces, mapping binding pockets, and aiding molecular replacement in X-ray crystallography.\n"]}]},{"cell_type":"code","source":["from google import genai\n","from google.genai import types\n","\n","import requests\n","\n","image_path = \"https://goo.gle/instrument-img\"\n","image_bytes = requests.get(image_path).content\n","image = types.Part.from_bytes(\n","  data=image_bytes, mime_type=\"image/webp\"\n",")\n","\n","client = genai.Client(api_key=\"AIzaSyD61Xx7KeCUm2zKbpbyVHdI2j-tVtQk1a0\")\n","\n","response = client.models.generate_content(\n","    model=\"gemini-2.5-flash\",\n","    contents=[\"What is this image?\", image],\n",")\n","\n","print(response.text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J9u1L3FMyPRc","executionInfo":{"status":"ok","timestamp":1757409906398,"user_tz":-330,"elapsed":7235,"user":{"displayName":"Mridul","userId":"15215068258986362506"}},"outputId":"940202f5-a4e3-4f7f-c080-df8541ded280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["This image shows the console of a **digital organ**.\n","\n","Key features visible include:\n","*   **Multiple manuals:** Several rows of piano-like keyboards for the hands.\n","*   **Stop tabs:** Numerous white and black rectangular tabs on the side panels and above the manuals, used to select different voices or \"stops\" (emulating the different ranks of pipes on a pipe organ).\n","*   **Pedalboard:** A set of larger, wooden keys at the bottom, played with the feet.\n","*   **Expression/Swell pedals:** The black rectangular pedals above the pedalboard, used to control volume or dynamics for different divisions of the organ.\n","*   **Piston buttons:** Round brass-colored buttons, often used for quickly selecting preset combinations of stops.\n","*   A small digital display (e.g., \"88\") which is common on modern digital organs for showing memory presets or other settings.\n","\n","This type of console is designed to provide the full playing experience of a traditional pipe organ, but generates sounds electronically rather than through actual pipes.\n"]}]}]}